{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dffd7e21",
   "metadata": {},
   "source": [
    "# Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fe81c9",
   "metadata": {},
   "source": [
    "Here I work with $\\textbf{MNIST Handwritten Digits Dataset}$. It contains 70,000 grayscale images of handwritten digits (0–9), with 60,000 images in the training set and 10,000 in the test set. Each image is 28×28 pixels in size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef8efd9",
   "metadata": {},
   "source": [
    "$\\spadesuit$ First I fit a neural network to the true data. Then I perform PCA to obtain a transformed data of reduced dimension and again the same netural network is fit to the transformed data. Finally, I compare the performance of the two neural network models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8168b820",
   "metadata": {},
   "source": [
    "# Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eecb9d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab78eaa",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d9d86f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8fc6bd",
   "metadata": {},
   "source": [
    "Right now we do not want train and test data seperately (For PCA we need the whole data, not split data). So we shall merge them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6497c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3eba621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating the images\n",
    "images = np.concatenate((train_images, test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3f02be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating the labels\n",
    "labels = np.concatenate((train_labels, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b28ca49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 28, 28)\n",
      "(70000,)\n"
     ]
    }
   ],
   "source": [
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8252857c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(images), type(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce15c508",
   "metadata": {},
   "source": [
    "# A look at a randomly selected example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a44c0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index = 26952\n",
      "Label = 8\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.set_printoptions(linewidth = 320)\n",
    "\n",
    "index = np.random.randint(0, 70000)\n",
    "\n",
    "print(f\"index = {index}\")\n",
    "print(f\"Label = {labels[index]}\")\n",
    "\n",
    "plt.imshow(images[index], cmap='Greys')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4d8682",
   "metadata": {},
   "source": [
    "# Fitting a neural network on the true data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79674930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating training_set and test_set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=1/7, random_state=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da7a30fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8dcabeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(28, 28)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(units=128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(units=32, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(units=10, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a906cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.compile(optimizer=tf.optimizers.Adam(),\n",
    "               loss='sparse_categorical_crossentropy',\n",
    "               metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1590aec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 24s 12ms/step - loss: 0.9048 - accuracy: 0.8491\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2713 - accuracy: 0.9333\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.1837 - accuracy: 0.9517\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.1390 - accuracy: 0.9630\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.1059 - accuracy: 0.9703\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0925 - accuracy: 0.9749\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0815 - accuracy: 0.9781\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0709 - accuracy: 0.9806\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0653 - accuracy: 0.9829\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0590 - accuracy: 0.9843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bf89cc06d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.fit(train_images, train_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a66d94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1523 - accuracy: 0.9687\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.15231972932815552, 0.9686999917030334]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f007f9",
   "metadata": {},
   "source": [
    "# Performing PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58516fb3",
   "metadata": {},
   "source": [
    "Now we shall obtain a transformed data by Principal Component Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ebaa617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the data\n",
    "images_reshaped = images.reshape(70000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58c29246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "images_standardized = scaler.fit_transform(images_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a20ff90",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues, eigenvectors = np.linalg.eig(np.cov(images_standardized, rowvar=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37eab123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9013012620427753\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(eigenvalues[0:500])/784)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d12f573",
   "metadata": {},
   "source": [
    "So we observe that first 500 principal components explain about 90% of total variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ea7ffa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3963f8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_transformed = pca.fit_transform(images_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "711e4549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 500)\n"
     ]
    }
   ],
   "source": [
    "print(images_transformed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8352f3f2",
   "metadata": {},
   "source": [
    "# Fitting same neural network on transformed data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f859ea6",
   "metadata": {},
   "source": [
    "Our transformed data has 70000 examples with 500 columns. Now we shall apply the same neural network on this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad63c419",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_transformed, test_images_transformed, train_labels, test_labels = train_test_split(images_transformed, labels, test_size=1/7, random_state=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d296acf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 500)\n",
      "(60000,)\n",
      "(10000, 500)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_images_transformed.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_images_transformed.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d2a8462",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(500,)),\n",
    "    tf.keras.layers.Dense(units=512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(units=128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(units=32, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(units=10, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1878b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(optimizer=tf.optimizers.Adam(),\n",
    "               loss = 'sparse_categorical_crossentropy',\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9731251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 20s 10ms/step - loss: 0.9344 - accuracy: 0.8391\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.2372 - accuracy: 0.9368\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.1725 - accuracy: 0.9536\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.1395 - accuracy: 0.9625\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.1191 - accuracy: 0.9681\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1169 - accuracy: 0.9706\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0826 - accuracy: 0.9789\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0820 - accuracy: 0.9795\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0783 - accuracy: 0.9803\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0745 - accuracy: 0.9830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bf82ceb1d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(train_images_transformed, train_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69b234b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1870 - accuracy: 0.9614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.18701964616775513, 0.9613999724388123]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.evaluate(test_images_transformed, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db73a829",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b560eaaa",
   "metadata": {},
   "source": [
    "Observe that, we reduced data dimension from 784 to 500. There is hardly any drop in accuracy in test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70ad2d1",
   "metadata": {},
   "source": [
    "Another point of view is 784 to 500 is not much of a drop where purpose of PCA is to have more dimension reduction. It cannot be said firmly that PCA has done well on this dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
